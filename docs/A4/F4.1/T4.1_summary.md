# T4.1: Feature Extractor & BanditSwitch v1 Summary

## What

Implemented BanditSwitch v1, a fast ε-greedy ridge linear contextual bandit for topology switching decisions among {stay, star, chain, flat}. The system uses an 8-feature state vector and maintains per-action ridge regression models with Sherman-Morrison updates for efficient inverse computation.

## How

### Feature Extractor (`apex/controller/features.py`)

Generates 8-dimensional feature vectors:
1. `topo_onehot_star`: 1 if current topology is star, else 0
2. `topo_onehot_chain`: 1 if current topology is chain, else 0  
3. `topo_onehot_flat`: 1 if current topology is flat, else 0
4. `steps_since_switch / K_dwell`: Normalized time since last switch [0,1]
5. `planner_share`: Planner messages / total in last K steps
6. `coder_runner_share`: (Coder + runner messages) / total in last K steps
7. `critic_share`: Critic messages / total in last K steps
8. `token_headroom_pct`: max(0, 1 - used/budget)

Uses a sliding window (deque) of size K=32 for O(1) append/pop operations on role counts.

### BanditSwitch v1 (`apex/controller/bandit_v1.py`)

**Action Mapping:**
```python
ACTION_MAP = {
    0: "stay",
    1: "star", 
    2: "chain",
    3: "flat"
}
```

**Ridge Linear Model:**
- Per-action parameters: A_a (8×8), b_a (8×1), w_a (8×1)
- Initialize: A_a = λI (λ=1e-2), b_a = 0
- Predict: r̂_a = w_a^T x
- Update: Sherman-Morrison formula for efficient A^(-1) computation

**Epsilon Schedule:**
- Linear decay: 0.20 → 0.05 over first 5,000 decisions
- Clipped to [0.05, 0.20]

**Latency Optimization:**
- Pure Python implementation (no I/O, no async)
- Sherman-Morrison updates avoid matrix inversion
- Uses `time.monotonic_ns()` for microsecond precision

### Controller Integration (`apex/controller/controller.py`)

Orchestrates the decide → switch → update cycle:
1. Build 8-feature vector from current state
2. Get bandit decision (action + epsilon + latency)
3. If action ≠ stay, request switch via Coordinator
4. Log decision to JSONL buffer
5. Update bandit with observed reward

## Why

**Design Choices:**

1. **Sherman-Morrison Updates**: Avoids O(d³) matrix inversion, uses O(d²) rank-1 update instead
2. **Sliding Window Deque**: Constant-time window management for role share computation
3. **Monotonic Clocks**: Ensures accurate microsecond-level latency measurements
4. **Action Index Mapping**: Consistent 0-3 indexing simplifies bandit mathematics

## API

```python
class BanditSwitchV1:
    def decide(self, x: list[float]) -> dict:
        """Returns {action: int, epsilon: float, ms: float}"""
    
    def update(self, x: list[float], action: int, reward: float) -> None:
        """Update model with observed reward"""
    
    def stats(self) -> dict:
        """Get decision counts and epsilon info"""

class FeatureSource:
    def observe_msg(self, sender: str) -> None:
        """Track role message"""
    
    def set_topology(self, topo: str, steps_since_switch: int) -> None:
        """Update topology state"""
    
    def vector(self) -> list[float]:
        """Get 8-feature vector"""
```

## Performance Results

From `test_bandit_latency.py` over 10,000 decisions:

```
Latency stats over 10k decisions:
  p50: 0.042 ms
  p95: 0.083 ms
  min: 0.029 ms
  max: 2.417 ms
```

**✅ p95 < 10ms requirement satisfied (0.083ms << 10ms)**

Artifact: `docs/A4/artifacts/controller_latency.jsonl`

## Test Commands

```bash
pip install -e ".[dev]"
pytest -q tests/test_features_v1.py
pytest -q tests/test_bandit_latency.py
```

## Code References

- Feature extractor: `apex/controller/features.py:24-124`
- Bandit policy: `apex/controller/bandit_v1.py:29-155`
- Controller integration: `apex/controller/controller.py:13-151`
- Latency test: `tests/test_bandit_latency.py:11-95`